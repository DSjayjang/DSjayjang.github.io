---
layout: single
title: "Convolutional Neural Network (CNN, 합성곱 신경망)"
categories: Deep-Learning
tag: [machine-learning, deep-learning, convolutional-neural-network, cnn]
toc: true # 목차 보여주기
author_profile: false   # 프로필 제거
# sidebar:    # 프로필 제거 후 사이드바 보여주기
#     nav: "counts"
typora-root-url: ../
---

# ※ Convolutional Neural Network
- 이미지 처리와 패턴 인식에 탁월한 성능을 보여주는 신경망
- 이미지 데이터의 공간적 특징을 추출하여 학습하고 이를 기반으로 패턴을 인식하는데 사용
- 구성
  - Convolution Layer (합성곱 층)
  - Pooling Layer (풀링 층)
  - Fully-Connected Layer (완전하게 연결된 층)
- 전체적인 절차
  1. Input (이미지)
  2. Convolution Layer에서 Filter를 통해 Feature map 생성
  3. Pooling을 통해 Feature map 크기를 줄임
  4. 2~3 반복
  5. Flatten
  6. NN

![1]({{site.url}}/images/dl/cnn/1.jpg)



<br>

## ■ Convolution Layer (합성곱 층)

### □ Filter (Kernel)
- 이미지를 스캔하기 위한 가중치들의 집합
- 가중치: CNN에서는 학습해야 할 가중치를 '가로세로 넓이를 갖는 하나의 작은 면 형태의 세트'로 구성됨

<br>

### □ Feature Map (특성 시트 / Activation Map)
- Filter로 연산된 결과 (필터 개수만큼 생성됨)
- Filter가 읽어낸 특성값들을 나열하면 다시 가로세로의 면이 된 것
- e.g. 3x3 filter =$\sum_{i,j} w_{ij} \times x_{ij}$
- activation function으로는 보통 ReLU 사용

<br>

![2]({{site.url}}/images/dl/cnn/2.jpg)



- 이미지 처리와 패턴 인식을 위해 주로 사용되는 구성 요소
- input image와 kernel(filter) 간의 합성곱 연산을 통해 새로운 특성 맵(feature map / activation map)을 생성
- kernel의 크기와 보폭(stride)은 합성곱 층의 출력(feature map)의 크기를 조절하는 요소
  - e.g. stride=1 인 경우 한칸씩 움직이며 합성곱 연산
  - kernel의 사이즈가 작으면 디테일한 feature도 처리할수있게 되지만 연산량 증가해서 적정 값을 찾는게 중요함
- feature map 크기가 클수록 feature의 디테일 표현 가능
- 보통 활성화 함수를 사용하여 비선형성 도입 (보통 ReLU함수)

<br>

### □ Stride (보폭)
- filter를 한번에 이동시키는 값
  - e.g. stride = 1 : filter를 한번에 한칸씩 이동시킴

<br>

### e.g.
84x84x4 짜리 >> fiter size=8x8, stride=4, filter 개수는 32개일 때, 출력되는 사이즈는 8+4x=84 >> x = 19
(19+1) = 20
20x20x32 >> fiter size=4x4, stride=2, filter 개수는 64개일 때, 출력되는 사이즈는 4+2x=20 >> x = 8
(8+1) = 9
9x9x64

<br>

## Pooling Layer (풀링 층)
- 합성곱 층에서 추출된 feature map의 크기를 줄이는 역할
  - 최대 풀링층: 주어진 풀링 윈도우 내의 값의 최대값 리턴
  - 평균 풀링층: 주어진 풀링 윈도우 내의 값의 평균값 리턴
- 풀링층을 통해 공간크기를 줄이고 계산비용을 줄이면서 특징 보존

<br>

### □ Max pooling
- filter를 거쳐 만들어진 윤곽의 이미지 사이즈를 줄이기 위한 방법
- 샘플링해서 이미지 사이즈를 줄임

<br>

## Dense Layer (밀집 층)
- 추출된 feature들을 기반으로 최종 출력 생성 
- Fully-Connected layer전에 모든 local feature를 1차원으로 만들어주는 flatten층을 배치함

convolution > pooling > convolution > pooling > ... > dense


### flatten
- 2D array를 한줄로 펼침


### embedding
- fully connected layer 전까지의 과정 (feature extraction)