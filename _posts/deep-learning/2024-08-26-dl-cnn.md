---
layout: single
title: "Convolutional Neural Network (CNN, 합성곱 신경망)"
categories: Deep-Learning
tag: [machine-learning, deep-learning, convolutional-neural-network, cnn]
toc: true # 목차 보여주기
author_profile: false   # 프로필 제거
# sidebar:    # 프로필 제거 후 사이드바 보여주기
#     nav: "counts"
typora-root-url: ../
---

# Convolutional Neural Network
- 이미지 처리와 패턴 인식에 탁월한 성능을 보여주는 신경망
- 이미지 데이터의 공간적 특징을 추출하여 학습하고 이를 기반으로 패턴을 인식하는데 사용
- 구성
  - Convolution Layer (합성곱 층)
  - Pooling Layer (풀링 층)
  - Fully-Connected Layer (완전하게 연결된 층)

![1]({{site.url}}/images/dl/cnn/1.jpg)



<br>

## Convolution Layer (합성곱 층)

![2]({{site.url}}/images/dl/cnn/2.jpg)

CNN: 이미지 계열의 모델
RNN: 텍스트 계열의 모델

- 합성곱 층 convolutional layer
  - 이미지 처리와 패턴 인식을 위해 주로 사용되는 구성 요소
  - input image와 kernel(.필터) 간의 합성곱 연산을 통해 새로운 특성 맵(feature map)을 생성
  - kernel의 크기와 보폭(stride)은 합성곱층의 출력층의 크기를 조절하는 요소
  - feature map 크기가 클수록 feature의 디테일 표현 가능
  - kernel의 사이즈가 작으면 디테일한 feature도 처리할수있게 되지만 연산량 증가해서 적정값을 찾는게 즁요
  - stride가 1일 경우 한칸씩 움직이며 합성곱연산
  - 커널의 크기가 같아도 보폭에 따라서 feature map이 달라짐
  - 보통 활성화함수를 사용하여 비선형성 도입 (보통 ReLU함수)
- 풀링층 (pooling lyaer)
  - 합성곱층에서 추출된 feauture .map 크기를 줄이는 역할
  - 최대풀링층
  - 평균풀링층: 주어진 풀링 윈도우 내의 값의 평균값 리턴
  - 풀링층을 통해 공간크기를 줄이고 계산비용을 줄이면서 특징 보존
- 밀집층 dense layer
  - 추출된 feature들을 기반ㅇ로 최종 출ㄹ력 생성 
  - fully connected layer전에 모든 local feature를 1차원으로 만ㄷㅡㄹ어주는 flatten층을 배치함

convolution > pooling > convolution > pooling > ... > dense


flatten: 2D array를 한줄로 펼침,,,
>> 정보가 손실되지 않게 요약해서 만들면 어떨까... >> CNN

filter(kernel): 이미지 스캔
activation function으로는 보통 ReLU 사용
activation map : filter로 연산한 결과 / 필터 개수만큼 만들어짐
e.g. 3x3 filter =$\sum_{i,j} w_{ij} \times x_{ij}$

embedding: fully connected layer 전까지의 과정 (feature extraction)

# ResNet
gradient update가 잘 안되는 문제를 해결 (gredient vanishing)

gradient 정보를 앞쪽까지 잘 전달해 주자.
loss를 하나는 레이어를 지나고,,, 하나는 살아서 그냥 넘기고,,,  f(x)+x
